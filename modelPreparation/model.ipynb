{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Libraries to be imported \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score, mean_squared_error,classification_report,roc_curve,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General_Health</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Heart_Disease</th>\n",
       "      <th>Skin_Cancer</th>\n",
       "      <th>Other_Cancer</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Arthritis</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age_Category</th>\n",
       "      <th>Height_(cm)</th>\n",
       "      <th>Weight_(kg)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking_History</th>\n",
       "      <th>Alcohol_Consumption</th>\n",
       "      <th>Fruit_Consumption</th>\n",
       "      <th>Green_Vegetables_Consumption</th>\n",
       "      <th>FriedPotato_Consumption</th>\n",
       "      <th>SexBinary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>55-59</td>\n",
       "      <td>170.0</td>\n",
       "      <td>68.04</td>\n",
       "      <td>23.49</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>80+</td>\n",
       "      <td>168.0</td>\n",
       "      <td>77.11</td>\n",
       "      <td>27.44</td>\n",
       "      <td>Yes</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>80+</td>\n",
       "      <td>175.0</td>\n",
       "      <td>72.57</td>\n",
       "      <td>23.63</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>55-59</td>\n",
       "      <td>180.0</td>\n",
       "      <td>99.79</td>\n",
       "      <td>30.68</td>\n",
       "      <td>No</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>30-34</td>\n",
       "      <td>188.0</td>\n",
       "      <td>70.31</td>\n",
       "      <td>19.90</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  General_Health Exercise Heart_Disease Skin_Cancer Other_Cancer Depression  \\\n",
       "0      Very Good      Yes            No          No           No         No   \n",
       "1      Excellent       No            No          No           No         No   \n",
       "2           Good      Yes            No         Yes           No         No   \n",
       "3      Very Good      Yes            No          No           No         No   \n",
       "4           Good      Yes            No          No           No         No   \n",
       "\n",
       "  Diabetes Arthritis     Sex Age_Category  Height_(cm)  Weight_(kg)    BMI  \\\n",
       "0       No       Yes  Female        55-59        170.0        68.04  23.49   \n",
       "1       No        No  Female          80+        168.0        77.11  27.44   \n",
       "2       No       Yes  Female          80+        175.0        72.57  23.63   \n",
       "3       No        No    Male        55-59        180.0        99.79  30.68   \n",
       "4       No       Yes    Male        30-34        188.0        70.31  19.90   \n",
       "\n",
       "  Smoking_History  Alcohol_Consumption  Fruit_Consumption  \\\n",
       "0              No                  0.0               90.0   \n",
       "1             Yes                 30.0                2.0   \n",
       "2              No                  0.0               60.0   \n",
       "3              No                 20.0               30.0   \n",
       "4             Yes                 24.0                8.0   \n",
       "\n",
       "   Green_Vegetables_Consumption  FriedPotato_Consumption  SexBinary  \n",
       "0                           4.0                      1.0          0  \n",
       "1                          30.0                      0.0          0  \n",
       "2                          20.0                      1.0          0  \n",
       "3                          16.0                      4.0          1  \n",
       "4                          24.0                     20.0          1  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Data to be used\n",
    "data = pd.read_csv('forModel.csv')\n",
    "data.drop(['Checkup','Unnamed: 0.1','Unnamed: 0'], axis = 1, inplace =True)\n",
    "\n",
    "##Cloned Data \n",
    "clonedData = pd.read_csv('forModel.csv')\n",
    "clonedData['Heart_Disease'] = clonedData['Heart_Disease'].map({'Yes':1,'No':0})\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation ! \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 160000 rows and 19 columns\n",
      "General_Health                   object\n",
      "Exercise                         object\n",
      "Heart_Disease                    object\n",
      "Skin_Cancer                      object\n",
      "Other_Cancer                     object\n",
      "Depression                       object\n",
      "Diabetes                         object\n",
      "Arthritis                        object\n",
      "Sex                              object\n",
      "Age_Category                     object\n",
      "Height_(cm)                     float64\n",
      "Weight_(kg)                     float64\n",
      "BMI                             float64\n",
      "Smoking_History                  object\n",
      "Alcohol_Consumption             float64\n",
      "Fruit_Consumption               float64\n",
      "Green_Vegetables_Consumption    float64\n",
      "FriedPotato_Consumption         float64\n",
      "SexBinary                         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## lets first evaluate the datas that we will be using ! \n",
    "\n",
    "print(f\"The data has {data.shape[0]} rows and {data.shape[1]} columns\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique features that the columns General_Health has is 5\n",
      "The number of unique features that the columns Exercise has is 2\n",
      "The number of unique features that the columns Heart_Disease has is 2\n",
      "The number of unique features that the columns Skin_Cancer has is 2\n",
      "The number of unique features that the columns Other_Cancer has is 2\n",
      "The number of unique features that the columns Depression has is 2\n",
      "The number of unique features that the columns Diabetes has is 4\n",
      "The number of unique features that the columns Arthritis has is 2\n",
      "The number of unique features that the columns Sex has is 2\n",
      "The number of unique features that the columns Age_Category has is 13\n",
      "The number of unique features that the columns Smoking_History has is 2\n"
     ]
    }
   ],
   "source": [
    "## Lets convert few columns in order to create few \n",
    "##Lets use the One Hot Encoder to change all the categorical data into the numerical datatypes \n",
    "onlyCategorical = data.select_dtypes(\"object\")\n",
    "for everything in onlyCategorical.columns:\n",
    "    print(f\"The number of unique features that the columns {everything} has is {data[everything].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## As seen lets convert the binary category using the .map and nominal category using the onehotencoding \n",
    "data['General_Health'] = data['General_Health'].apply(lambda x: 'Poor' if x == 'Poor' else 'Good')\n",
    "data['General_Health'] = data['General_Health'].map({\"Poor\":1, \"Good\":0})\n",
    "data['Sex'] = data['Sex'].map({'Male':1, 'Female':0})\n",
    "data['Diabetes'] = data['Diabetes'].apply(lambda x:'No' if x == 'No' else 'Yes')\n",
    "## Since most of the Binary have Yes and No we will convert all of them at once \n",
    "cols = ['Exercise','Heart_Disease','Skin_Cancer','Other_Cancer','Depression','Arthritis','Smoking_History','Diabetes']\n",
    "for each in cols:\n",
    "    data[each] = data[each].map({'Yes':1,'No':0}) ##This converts the whole data into the binary \n",
    "\n",
    "dummied_data = pd.get_dummies(data, columns=['Age_Category'], dtype = 'int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The reason to convert the binary categories using the .map instead of using OneHotEncoding is to minimize the number of columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets figure out the independent variable and dependent varibale \n",
    "SEED = 9\n",
    "X = dummied_data.drop('Heart_Disease', axis = 1)\n",
    "y = clonedData['Heart_Disease']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2, random_state = SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be selecting the best models among the LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, AdaBoostClassifer, GradientBoostClassifer through its ROC_AUC_SCORE and other different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.73     15927\n",
      "           1       0.73      0.77      0.75     16073\n",
      "\n",
      "    accuracy                           0.74     32000\n",
      "   macro avg       0.74      0.74      0.74     32000\n",
      "weighted avg       0.74      0.74      0.74     32000\n",
      "\n",
      "0.8151259230704846\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Logistic Regression \n",
    "\n",
    "##Pipeline Preparation \n",
    "pipeline_steps = [('imputer',SimpleImputer(strategy='median')),('scalar',StandardScaler()),('logit',LogisticRegression(solver='liblinear',max_iter=1000))]\n",
    "logit_pipeline = Pipeline(pipeline_steps)\n",
    "\n",
    "##Lets do the hyperparameer tuining \n",
    "params = {'logit__C':[0.01,0.1],'logit__penalty':['l1','l2']}\n",
    "hyper_tuning = RandomizedSearchCV(logit_pipeline, param_distributions= params, cv = 3, n_jobs=-1, n_iter=4) ## The best parameter has been calcuated and updated accordingly in the logit_model \n",
    "hyper_tuning.fit(X_train,y_train)\n",
    "hyper_tuned_model = hyper_tuning.best_estimator_\n",
    "training_predict = hyper_tuned_model.predict(X_train)\n",
    "testing_predict = hyper_tuned_model.predict(X_test)\n",
    "probabilites_predict = hyper_tuned_model.predict_proba(X_test)[:,1]\n",
    "logit_training_score = accuracy_score(y_train,training_predict) #0.74\n",
    "\n",
    "logit_testing_score = accuracy_score(y_test,testing_predict) #0.74\n",
    "## classification report \n",
    "class_report_logit = classification_report(y_test, testing_predict)\n",
    "print(class_report_logit) \n",
    "##ROC AUC score \n",
    "fpr, tpr, thresholds = roc_curve(y_test,probabilites_predict)\n",
    "logit_roc_score = roc_auc_score(y_test,probabilites_predict) ##81%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The logistic regression model has 76% precision, 71%recall, and 73% f1-score. Whereas, the training and testing score is equaivalent(~74%) which means the model has no problem with over fitting and underfitting. Also, the roc score of the model is 81% which is good "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

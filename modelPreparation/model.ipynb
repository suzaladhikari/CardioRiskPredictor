{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Libraries to be imported \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score, mean_squared_error,classification_report,roc_curve,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV,cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>General_Health</th>\n",
       "      <th>Exercise</th>\n",
       "      <th>Heart_Disease</th>\n",
       "      <th>Skin_Cancer</th>\n",
       "      <th>Other_Cancer</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Arthritis</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age_Category</th>\n",
       "      <th>Height_(cm)</th>\n",
       "      <th>Weight_(kg)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking_History</th>\n",
       "      <th>Alcohol_Consumption</th>\n",
       "      <th>Fruit_Consumption</th>\n",
       "      <th>Green_Vegetables_Consumption</th>\n",
       "      <th>FriedPotato_Consumption</th>\n",
       "      <th>SexBinary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>55-59</td>\n",
       "      <td>170.0</td>\n",
       "      <td>68.04</td>\n",
       "      <td>23.49</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>80+</td>\n",
       "      <td>168.0</td>\n",
       "      <td>77.11</td>\n",
       "      <td>27.44</td>\n",
       "      <td>Yes</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>80+</td>\n",
       "      <td>175.0</td>\n",
       "      <td>72.57</td>\n",
       "      <td>23.63</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>55-59</td>\n",
       "      <td>180.0</td>\n",
       "      <td>99.79</td>\n",
       "      <td>30.68</td>\n",
       "      <td>No</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Male</td>\n",
       "      <td>30-34</td>\n",
       "      <td>188.0</td>\n",
       "      <td>70.31</td>\n",
       "      <td>19.90</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  General_Health Exercise  ... FriedPotato_Consumption SexBinary\n",
       "0      Very Good      Yes  ...                     1.0         0\n",
       "1      Excellent       No  ...                     0.0         0\n",
       "2           Good      Yes  ...                     1.0         0\n",
       "3      Very Good      Yes  ...                     4.0         1\n",
       "4           Good      Yes  ...                    20.0         1\n",
       "\n",
       "[5 rows x 19 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Data to be used\n",
    "data = pd.read_csv('forModel.csv')\n",
    "data.drop(['Checkup','Unnamed: 0.1','Unnamed: 0'], axis = 1, inplace =True)\n",
    "\n",
    "##Cloned Data \n",
    "clonedData = pd.read_csv('forModel.csv')\n",
    "clonedData['Heart_Disease'] = clonedData['Heart_Disease'].map({'Yes':1,'No':0})\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation ! \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 160000 rows and 19 columns\n",
      "General_Health                   object\n",
      "Exercise                         object\n",
      "Heart_Disease                    object\n",
      "Skin_Cancer                      object\n",
      "Other_Cancer                     object\n",
      "Depression                       object\n",
      "Diabetes                         object\n",
      "Arthritis                        object\n",
      "Sex                              object\n",
      "Age_Category                     object\n",
      "Height_(cm)                     float64\n",
      "Weight_(kg)                     float64\n",
      "BMI                             float64\n",
      "Smoking_History                  object\n",
      "Alcohol_Consumption             float64\n",
      "Fruit_Consumption               float64\n",
      "Green_Vegetables_Consumption    float64\n",
      "FriedPotato_Consumption         float64\n",
      "SexBinary                         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "## lets first evaluate the datas that we will be using ! \n",
    "\n",
    "print(f\"The data has {data.shape[0]} rows and {data.shape[1]} columns\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique features that the columns General_Health has is 5\n",
      "The number of unique features that the columns Exercise has is 2\n",
      "The number of unique features that the columns Heart_Disease has is 2\n",
      "The number of unique features that the columns Skin_Cancer has is 2\n",
      "The number of unique features that the columns Other_Cancer has is 2\n",
      "The number of unique features that the columns Depression has is 2\n",
      "The number of unique features that the columns Diabetes has is 4\n",
      "The number of unique features that the columns Arthritis has is 2\n",
      "The number of unique features that the columns Sex has is 2\n",
      "The number of unique features that the columns Age_Category has is 13\n",
      "The number of unique features that the columns Smoking_History has is 2\n"
     ]
    }
   ],
   "source": [
    "## Lets convert few columns in order to create few \n",
    "##Lets use the One Hot Encoder to change all the categorical data into the numerical datatypes \n",
    "onlyCategorical = data.select_dtypes(\"object\")\n",
    "for everything in onlyCategorical.columns:\n",
    "    print(f\"The number of unique features that the columns {everything} has is {data[everything].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## As seen lets convert the binary category using the .map and nominal category using the onehotencoding \n",
    "data['General_Health'] = data['General_Health'].apply(lambda x: 'Poor' if x == 'Poor' else 'Good')\n",
    "data['General_Health'] = data['General_Health'].map({\"Poor\":1, \"Good\":0})\n",
    "data['Sex'] = data['Sex'].map({'Male':1, 'Female':0})\n",
    "data['Diabetes'] = data['Diabetes'].apply(lambda x:'No' if x == 'No' else 'Yes')\n",
    "## Since most of the Binary have Yes and No we will convert all of them at once \n",
    "cols = ['Exercise','Heart_Disease','Skin_Cancer','Other_Cancer','Depression','Arthritis','Smoking_History','Diabetes']\n",
    "for each in cols:\n",
    "    data[each] = data[each].map({'Yes':1,'No':0}) ##This converts the whole data into the binary \n",
    "\n",
    "dummied_data = pd.get_dummies(data, columns=['Age_Category'], dtype = 'int')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The reason to convert the binary categories using the .map instead of using OneHotEncoding is to minimize the number of columns. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets figure out the independent variable and dependent varibale \n",
    "SEED = 9\n",
    "X = dummied_data.drop('Heart_Disease', axis = 1)\n",
    "y = clonedData['Heart_Disease']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2, random_state = SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will be selecting the best models among the LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, AdaBoostClassifer, GradientBoostClassifer through its ROC_AUC_SCORE and other different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Model One : Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pipeline Preparation \n",
    "pipeline_steps = [('imputer',SimpleImputer(strategy='median')),('scalar',StandardScaler()),('logit',LogisticRegression(solver='liblinear',max_iter=1000))]\n",
    "logit_pipeline = Pipeline(pipeline_steps)\n",
    "\n",
    "##Lets do the hyperparameer tuining \n",
    "params = {'logit__C':[0.01,0.1],'logit__penalty':['l1','l2']}\n",
    "hyper_tuning = RandomizedSearchCV(logit_pipeline, param_distributions= params, cv = 3, n_jobs=-1, n_iter=4) ## The best parameter has been calcuated and updated accordingly in the logit_model \n",
    "hyper_tuning.fit(X_train,y_train)\n",
    "hyper_tuned_model = hyper_tuning.best_estimator_\n",
    "training_predict = hyper_tuned_model.predict(X_train)\n",
    "testing_predict = hyper_tuned_model.predict(X_test)\n",
    "probabilites_predict = hyper_tuned_model.predict_proba(X_test)[:,1]\n",
    "logit_training_score = accuracy_score(y_train,training_predict) #0.74\n",
    "\n",
    "logit_testing_score = accuracy_score(y_test,testing_predict) #0.74\n",
    "## classification report \n",
    "class_report_logit = classification_report(y_test, testing_predict)\n",
    "##ROC AUC score \n",
    "logit_fpr, logit_tpr, logit_thresholds = roc_curve(y_test,probabilites_predict)\n",
    "logit_roc_score = roc_auc_score(y_test,probabilites_predict) ##81%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The logistic regression model has 76% precision, 71%recall, and 73% f1-score. Whereas, the training and testing score is equaivalent(~74%) which means the model has no problem with over fitting and underfitting. Also, the roc score of the model is 81% which is good \n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Two: Decision Tree Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline Preparation \n",
    "decision_steps = [('Imputer',SimpleImputer(strategy='median')),('Scalar',StandardScaler()),('DecisionTree',DecisionTreeClassifier(random_state=SEED, class_weight='balanced'))] ## This is the pipeline we will be using \n",
    "decision_pipeline = Pipeline(decision_steps)\n",
    "#cross validation \n",
    "params = {'DecisionTree__max_depth':[3,4,5,6,7], 'DecisionTree__max_features':['sqrt','log2',None, 0.5]}\n",
    "cross_validation = cross_val_score(decision_pipeline, X,y, cv=5, scoring='roc_auc')\n",
    "#Hyperparameter tuning\n",
    "decision_hyper_tuning = RandomizedSearchCV(decision_pipeline, param_distributions=params, cv = 5, n_jobs = -1, n_iter = 20)\n",
    "decision_hyper_tuning.fit(X_train,y_train)\n",
    "best_decision_model = decision_hyper_tuning.best_estimator_\n",
    "decision_training_predict = best_decision_model.predict(X_train) #predicting the training accuracy \n",
    "decision_testing_predict = best_decision_model.predict(X_test) #prediciting the testing accuracy\n",
    "decision_predicited_proba = best_decision_model.predict_proba(X_test)[:,1] \n",
    "decision_testing_accuracy_score = accuracy_score(y_test, decision_testing_predict) # Testing Accuracy -> 0.72\n",
    "decision_training_accuracy_score = accuracy_score(y_train, decision_training_predict) # Training Accuracy -> 0.72\n",
    "\n",
    "##Classification report -> Analysis of precision, recall and f1 score\n",
    "decision_classification = classification_report(y_test, decision_testing_predict)\n",
    "decision_fpr, decision_tpr, decision_thresholds = roc_curve(y_test, decision_predicited_proba)\n",
    "decision_roc_score = roc_auc_score(y_test, decision_predicited_proba) ## 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The logistic regression model has 75% precision, 67%recall, and 71% f1-score. Whereas, the training and testing score is equaivalent(~72%) which means the model has no problem with over fitting and underfitting. Also, the roc score of the model is 78%\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Three: Bagging Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline Preparation \n",
    "decision_steps = [(\"imputer\",SimpleImputer()),(\"decision_tree\",DecisionTreeClassifier())]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
